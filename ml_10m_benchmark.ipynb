{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf,col,collect_list\n",
    "from pyspark.sql.types import StringType, ArrayType, DoubleType,IntegerType\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RankingEvaluator\n",
    "from HR import HitRate\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "#For windows user only\n",
    "import os \n",
    "import sys\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.utils.notebook_utils import is_jupyter\n",
    "from recommenders.datasets.spark_splitters import spark_random_split\n",
    "from recommenders.evaluation.spark_evaluation import SparkRatingEvaluation, SparkRankingEvaluation\n",
    "from recommenders.utils.spark_utils import start_or_get_spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/10/08 17:53:38 WARN Utils: Your hostname, lap15450-ThinkPad-X13-Gen-2i resolves to a loopback address: 127.0.1.1; using 192.168.0.193 instead (on interface wlp0s20f3)\n",
      "22/10/08 17:53:38 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/lap15450/.local/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.0.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/10/08 17:53:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\") \\\n",
    "                    .config('spark.ui.showConsoleProgress', 'false')\\\n",
    "                    .config('spark.driver.memory', '12g')\\\n",
    "                    .config('spark.executor.memory', '2g')\\\n",
    "                    .appName('MovieRecomender') \\\n",
    "                    .getOrCreate()\n",
    "                    \n",
    "spark.sparkContext.setCheckpointDir('checkpoint/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema =             StructType([\n",
    "                    StructField('UserID', LongType(), True),\n",
    "                     StructField('MovieID', LongType(), True),\n",
    "                     StructField('Rating', IntegerType(), True),\n",
    "                     StructField('Timestamp', LongType(), True),\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7951824"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.option(\"sep\", \"::\").schema(schema).csv(\"data/ml-10m/ratings.dat\")\n",
    "df = df.toDF(*[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"])\n",
    "df.createOrReplaceTempView(\"dataset\");\n",
    "df = df.dropna()\n",
    "df.persist().count() #Force persist due to size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 20\n",
    "iter = 15\n",
    "regParam = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hit Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_hit_rate(als, left_out_df, keep_one_df, full_matrix, n_users):\n",
    "    hr_evaluator = HitRate(predictionCol='prediction', labelCol='Rating', userCol='UserID', itemCol = \"MovieID\")\n",
    "    value = hr_evaluator.eval(als, left_out_df, keep_one_df, full_matrix, n_users)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rmse(model, test):\n",
    "    rmse = RegressionEvaluator(metricName=\"rmse\", labelCol=\"Rating\", predictionCol=\"prediction\")       \n",
    "    predictions=model.transform(test).na.drop()\n",
    "    return rmse.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCDG at K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ndcg_at_k(model, full_matrix, train, test, k = 10):\n",
    "    recommendations = model.transform(full_matrix)\n",
    "    rank_eval = SparkRankingEvaluation(test, recommendations, k = k, col_user=\"UserID\", col_item=\"MovieID\", \n",
    "                                    col_rating=\"Rating\", col_prediction=\"prediction\", \n",
    "                                    relevancy_method=\"top_k\")\n",
    "    return rank_eval.ndcg_at_k()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left out 69873, training to evaluate hit rate on 7881951.\n"
     ]
    }
   ],
   "source": [
    "#Leave one out for calculating hit rate\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "windowSpec  = Window.partitionBy(\"UserID\").orderBy(F.col(\"Rating\").desc())\n",
    "tmp = df.withColumn(\"row_number\", row_number().over(windowSpec))      \n",
    "left_out_dataframe = tmp.filter(F.col(\"row_number\") != 1)\n",
    "keep_one_dataframe = tmp.filter(F.col(\"row_number\") == 1)\n",
    "left_out_count = left_out_dataframe.persist().count() #Force persist due to size\n",
    "keep_out_count = keep_one_dataframe.persist().count() #Force persist\n",
    "print(\"Left out {}, training to evaluate hit rate on {}.\".format(keep_out_count, left_out_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/10/08 17:56:33 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "22/10/08 17:56:33 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "22/10/08 17:56:34 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "22/10/08 17:56:34 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n"
     ]
    }
   ],
   "source": [
    "user_df = df.select(\"UserID\").distinct()\n",
    "movie_df = df.select(\"MovieID\").distinct()\n",
    "\n",
    "user_df.persist().count() #Force persist\n",
    "movie_df.persist().count() #Force persist\n",
    "full_matrix = user_df.crossJoin(movie_df)\n",
    "full_matrix.persist().count() #Force persist due to size\n",
    "\n",
    "#Count\n",
    "n_users = user_df.count()\n",
    "n_items = movie_df.count()\n",
    "\n",
    "als = ALS(\n",
    "    rank=rank,\n",
    "    maxIter=iter,\n",
    "    regParam=regParam,\n",
    "    \n",
    "    userCol=\"UserID\",\n",
    "    itemCol=\"MovieID\",\n",
    "    ratingCol=\"Rating\",\n",
    "    implicitPrefs=False,\n",
    "    coldStartStrategy='drop',\n",
    "    nonnegative=False,\n",
    ")            \n",
    "# NDCG and RMSE\n",
    "(train, test) = df.randomSplit([0.8, 0.2])  \n",
    "model = als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1207, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1033, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1211, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42305)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_21589/3603929504.py\", line 1, in <module>\n",
      "    ndcg = (evaluate_ndcg_at_k(model, full_matrix, train, test, k = 10))\n",
      "  File \"/tmp/ipykernel_21589/159118592.py\", line 3, in evaluate_ndcg_at_k\n",
      "    rank_eval = SparkRankingEvaluation(test, recommendations, k = k, col_user=\"UserID\", col_item=\"MovieID\",\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 284, in __init__\n",
      "    self._metrics = self._calculate_metrics()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 300, in _calculate_metrics\n",
      "    return RankingMetrics(self._items_for_user_all.rdd)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/mllib/evaluation.py\", line 418, in __init__\n",
      "    schema=sql_ctx._inferSchema(predictionAndLabels))\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/context.py\", line 227, in _inferSchema\n",
      "    return self.sparkSession._inferSchema(rdd, samplingRatio)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1464, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1446, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/context.py\", line 1118, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 128, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42305)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_21589/3603929504.py\", line 1, in <module>\n",
      "    ndcg = (evaluate_ndcg_at_k(model, full_matrix, train, test, k = 10))\n",
      "  File \"/tmp/ipykernel_21589/159118592.py\", line 3, in evaluate_ndcg_at_k\n",
      "    rank_eval = SparkRankingEvaluation(test, recommendations, k = k, col_user=\"UserID\", col_item=\"MovieID\",\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 284, in __init__\n",
      "    self._metrics = self._calculate_metrics()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 300, in _calculate_metrics\n",
      "    return RankingMetrics(self._items_for_user_all.rdd)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/mllib/evaluation.py\", line 418, in __init__\n",
      "    schema=sql_ctx._inferSchema(predictionAndLabels))\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/context.py\", line 227, in _inferSchema\n",
      "    return self.sparkSession._inferSchema(rdd, samplingRatio)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1464, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1446, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/context.py\", line 1118, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 128, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42305)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_21589/3603929504.py\", line 1, in <module>\n",
      "    ndcg = (evaluate_ndcg_at_k(model, full_matrix, train, test, k = 10))\n",
      "  File \"/tmp/ipykernel_21589/159118592.py\", line 3, in evaluate_ndcg_at_k\n",
      "    rank_eval = SparkRankingEvaluation(test, recommendations, k = k, col_user=\"UserID\", col_item=\"MovieID\",\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 284, in __init__\n",
      "    self._metrics = self._calculate_metrics()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 300, in _calculate_metrics\n",
      "    return RankingMetrics(self._items_for_user_all.rdd)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/mllib/evaluation.py\", line 418, in __init__\n",
      "    schema=sql_ctx._inferSchema(predictionAndLabels))\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/context.py\", line 227, in _inferSchema\n",
      "    return self.sparkSession._inferSchema(rdd, samplingRatio)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1464, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1446, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/context.py\", line 1118, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 128, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42305)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_21589/3603929504.py\", line 1, in <module>\n",
      "    ndcg = (evaluate_ndcg_at_k(model, full_matrix, train, test, k = 10))\n",
      "  File \"/tmp/ipykernel_21589/159118592.py\", line 3, in evaluate_ndcg_at_k\n",
      "    rank_eval = SparkRankingEvaluation(test, recommendations, k = k, col_user=\"UserID\", col_item=\"MovieID\",\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 284, in __init__\n",
      "    self._metrics = self._calculate_metrics()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 300, in _calculate_metrics\n",
      "    return RankingMetrics(self._items_for_user_all.rdd)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/mllib/evaluation.py\", line 418, in __init__\n",
      "    schema=sql_ctx._inferSchema(predictionAndLabels))\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/context.py\", line 227, in _inferSchema\n",
      "    return self.sparkSession._inferSchema(rdd, samplingRatio)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1464, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1446, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/context.py\", line 1118, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 128, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42305)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_21589/3603929504.py\", line 1, in <module>\n",
      "    ndcg = (evaluate_ndcg_at_k(model, full_matrix, train, test, k = 10))\n",
      "  File \"/tmp/ipykernel_21589/159118592.py\", line 3, in evaluate_ndcg_at_k\n",
      "    rank_eval = SparkRankingEvaluation(test, recommendations, k = k, col_user=\"UserID\", col_item=\"MovieID\",\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 284, in __init__\n",
      "    self._metrics = self._calculate_metrics()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 300, in _calculate_metrics\n",
      "    return RankingMetrics(self._items_for_user_all.rdd)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/mllib/evaluation.py\", line 418, in __init__\n",
      "    schema=sql_ctx._inferSchema(predictionAndLabels))\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/context.py\", line 227, in _inferSchema\n",
      "    return self.sparkSession._inferSchema(rdd, samplingRatio)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1464, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1446, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/context.py\", line 1118, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 128, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42305)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_21589/3603929504.py\", line 1, in <module>\n",
      "    ndcg = (evaluate_ndcg_at_k(model, full_matrix, train, test, k = 10))\n",
      "  File \"/tmp/ipykernel_21589/159118592.py\", line 3, in evaluate_ndcg_at_k\n",
      "    rank_eval = SparkRankingEvaluation(test, recommendations, k = k, col_user=\"UserID\", col_item=\"MovieID\",\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 284, in __init__\n",
      "    self._metrics = self._calculate_metrics()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 300, in _calculate_metrics\n",
      "    return RankingMetrics(self._items_for_user_all.rdd)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/mllib/evaluation.py\", line 418, in __init__\n",
      "    schema=sql_ctx._inferSchema(predictionAndLabels))\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/context.py\", line 227, in _inferSchema\n",
      "    return self.sparkSession._inferSchema(rdd, samplingRatio)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1464, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1446, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/context.py\", line 1118, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 128, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42305)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_21589/3603929504.py\", line 1, in <module>\n",
      "    ndcg = (evaluate_ndcg_at_k(model, full_matrix, train, test, k = 10))\n",
      "  File \"/tmp/ipykernel_21589/159118592.py\", line 3, in evaluate_ndcg_at_k\n",
      "    rank_eval = SparkRankingEvaluation(test, recommendations, k = k, col_user=\"UserID\", col_item=\"MovieID\",\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 284, in __init__\n",
      "    self._metrics = self._calculate_metrics()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 300, in _calculate_metrics\n",
      "    return RankingMetrics(self._items_for_user_all.rdd)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/mllib/evaluation.py\", line 418, in __init__\n",
      "    schema=sql_ctx._inferSchema(predictionAndLabels))\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/context.py\", line 227, in _inferSchema\n",
      "    return self.sparkSession._inferSchema(rdd, samplingRatio)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1464, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1446, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/context.py\", line 1118, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 128, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42305)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_21589/3603929504.py\", line 1, in <module>\n",
      "    ndcg = (evaluate_ndcg_at_k(model, full_matrix, train, test, k = 10))\n",
      "  File \"/tmp/ipykernel_21589/159118592.py\", line 3, in evaluate_ndcg_at_k\n",
      "    rank_eval = SparkRankingEvaluation(test, recommendations, k = k, col_user=\"UserID\", col_item=\"MovieID\",\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 284, in __init__\n",
      "    self._metrics = self._calculate_metrics()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 300, in _calculate_metrics\n",
      "    return RankingMetrics(self._items_for_user_all.rdd)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/mllib/evaluation.py\", line 418, in __init__\n",
      "    schema=sql_ctx._inferSchema(predictionAndLabels))\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/context.py\", line 227, in _inferSchema\n",
      "    return self.sparkSession._inferSchema(rdd, samplingRatio)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1464, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1446, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/context.py\", line 1118, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 128, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42305)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_21589/3603929504.py\", line 1, in <module>\n",
      "    ndcg = (evaluate_ndcg_at_k(model, full_matrix, train, test, k = 10))\n",
      "  File \"/tmp/ipykernel_21589/159118592.py\", line 3, in evaluate_ndcg_at_k\n",
      "    rank_eval = SparkRankingEvaluation(test, recommendations, k = k, col_user=\"UserID\", col_item=\"MovieID\",\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 284, in __init__\n",
      "    self._metrics = self._calculate_metrics()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 300, in _calculate_metrics\n",
      "    return RankingMetrics(self._items_for_user_all.rdd)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/mllib/evaluation.py\", line 418, in __init__\n",
      "    schema=sql_ctx._inferSchema(predictionAndLabels))\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/context.py\", line 227, in _inferSchema\n",
      "    return self.sparkSession._inferSchema(rdd, samplingRatio)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1464, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1446, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/context.py\", line 1118, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 128, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42305)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_21589/3603929504.py\", line 1, in <module>\n",
      "    ndcg = (evaluate_ndcg_at_k(model, full_matrix, train, test, k = 10))\n",
      "  File \"/tmp/ipykernel_21589/159118592.py\", line 3, in evaluate_ndcg_at_k\n",
      "    rank_eval = SparkRankingEvaluation(test, recommendations, k = k, col_user=\"UserID\", col_item=\"MovieID\",\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 284, in __init__\n",
      "    self._metrics = self._calculate_metrics()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 300, in _calculate_metrics\n",
      "    return RankingMetrics(self._items_for_user_all.rdd)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/mllib/evaluation.py\", line 418, in __init__\n",
      "    schema=sql_ctx._inferSchema(predictionAndLabels))\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/context.py\", line 227, in _inferSchema\n",
      "    return self.sparkSession._inferSchema(rdd, samplingRatio)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1464, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1446, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/context.py\", line 1118, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 128, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42305)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_21589/3603929504.py\", line 1, in <module>\n",
      "    ndcg = (evaluate_ndcg_at_k(model, full_matrix, train, test, k = 10))\n",
      "  File \"/tmp/ipykernel_21589/159118592.py\", line 3, in evaluate_ndcg_at_k\n",
      "    rank_eval = SparkRankingEvaluation(test, recommendations, k = k, col_user=\"UserID\", col_item=\"MovieID\",\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 284, in __init__\n",
      "    self._metrics = self._calculate_metrics()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 300, in _calculate_metrics\n",
      "    return RankingMetrics(self._items_for_user_all.rdd)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/mllib/evaluation.py\", line 418, in __init__\n",
      "    schema=sql_ctx._inferSchema(predictionAndLabels))\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/context.py\", line 227, in _inferSchema\n",
      "    return self.sparkSession._inferSchema(rdd, samplingRatio)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1464, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1446, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/context.py\", line 1118, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 128, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42305)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_21589/3603929504.py\", line 1, in <module>\n",
      "    ndcg = (evaluate_ndcg_at_k(model, full_matrix, train, test, k = 10))\n",
      "  File \"/tmp/ipykernel_21589/159118592.py\", line 3, in evaluate_ndcg_at_k\n",
      "    rank_eval = SparkRankingEvaluation(test, recommendations, k = k, col_user=\"UserID\", col_item=\"MovieID\",\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 284, in __init__\n",
      "    self._metrics = self._calculate_metrics()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 300, in _calculate_metrics\n",
      "    return RankingMetrics(self._items_for_user_all.rdd)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/mllib/evaluation.py\", line 418, in __init__\n",
      "    schema=sql_ctx._inferSchema(predictionAndLabels))\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/context.py\", line 227, in _inferSchema\n",
      "    return self.sparkSession._inferSchema(rdd, samplingRatio)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1464, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1446, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/context.py\", line 1118, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 128, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42305)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_21589/3603929504.py\", line 1, in <module>\n",
      "    ndcg = (evaluate_ndcg_at_k(model, full_matrix, train, test, k = 10))\n",
      "  File \"/tmp/ipykernel_21589/159118592.py\", line 3, in evaluate_ndcg_at_k\n",
      "    rank_eval = SparkRankingEvaluation(test, recommendations, k = k, col_user=\"UserID\", col_item=\"MovieID\",\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 284, in __init__\n",
      "    self._metrics = self._calculate_metrics()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 300, in _calculate_metrics\n",
      "    return RankingMetrics(self._items_for_user_all.rdd)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/mllib/evaluation.py\", line 418, in __init__\n",
      "    schema=sql_ctx._inferSchema(predictionAndLabels))\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/context.py\", line 227, in _inferSchema\n",
      "    return self.sparkSession._inferSchema(rdd, samplingRatio)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1464, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1446, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/context.py\", line 1118, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 128, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42305)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_21589/3603929504.py\", line 1, in <module>\n",
      "    ndcg = (evaluate_ndcg_at_k(model, full_matrix, train, test, k = 10))\n",
      "  File \"/tmp/ipykernel_21589/159118592.py\", line 3, in evaluate_ndcg_at_k\n",
      "    rank_eval = SparkRankingEvaluation(test, recommendations, k = k, col_user=\"UserID\", col_item=\"MovieID\",\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 284, in __init__\n",
      "    self._metrics = self._calculate_metrics()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 300, in _calculate_metrics\n",
      "    return RankingMetrics(self._items_for_user_all.rdd)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/mllib/evaluation.py\", line 418, in __init__\n",
      "    schema=sql_ctx._inferSchema(predictionAndLabels))\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/context.py\", line 227, in _inferSchema\n",
      "    return self.sparkSession._inferSchema(rdd, samplingRatio)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1464, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1446, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/context.py\", line 1118, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 128, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42305)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_21589/3603929504.py\", line 1, in <module>\n",
      "    ndcg = (evaluate_ndcg_at_k(model, full_matrix, train, test, k = 10))\n",
      "  File \"/tmp/ipykernel_21589/159118592.py\", line 3, in evaluate_ndcg_at_k\n",
      "    rank_eval = SparkRankingEvaluation(test, recommendations, k = k, col_user=\"UserID\", col_item=\"MovieID\",\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 284, in __init__\n",
      "    self._metrics = self._calculate_metrics()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 300, in _calculate_metrics\n",
      "    return RankingMetrics(self._items_for_user_all.rdd)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/mllib/evaluation.py\", line 418, in __init__\n",
      "    schema=sql_ctx._inferSchema(predictionAndLabels))\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/context.py\", line 227, in _inferSchema\n",
      "    return self.sparkSession._inferSchema(rdd, samplingRatio)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1464, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1446, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/context.py\", line 1118, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 128, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42305)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_21589/3603929504.py\", line 1, in <module>\n",
      "    ndcg = (evaluate_ndcg_at_k(model, full_matrix, train, test, k = 10))\n",
      "  File \"/tmp/ipykernel_21589/159118592.py\", line 3, in evaluate_ndcg_at_k\n",
      "    rank_eval = SparkRankingEvaluation(test, recommendations, k = k, col_user=\"UserID\", col_item=\"MovieID\",\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 284, in __init__\n",
      "    self._metrics = self._calculate_metrics()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 300, in _calculate_metrics\n",
      "    return RankingMetrics(self._items_for_user_all.rdd)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/mllib/evaluation.py\", line 418, in __init__\n",
      "    schema=sql_ctx._inferSchema(predictionAndLabels))\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/context.py\", line 227, in _inferSchema\n",
      "    return self.sparkSession._inferSchema(rdd, samplingRatio)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1464, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1446, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/context.py\", line 1118, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 128, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42305)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_21589/3603929504.py\", line 1, in <module>\n",
      "    ndcg = (evaluate_ndcg_at_k(model, full_matrix, train, test, k = 10))\n",
      "  File \"/tmp/ipykernel_21589/159118592.py\", line 3, in evaluate_ndcg_at_k\n",
      "    rank_eval = SparkRankingEvaluation(test, recommendations, k = k, col_user=\"UserID\", col_item=\"MovieID\",\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 284, in __init__\n",
      "    self._metrics = self._calculate_metrics()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 300, in _calculate_metrics\n",
      "    return RankingMetrics(self._items_for_user_all.rdd)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/mllib/evaluation.py\", line 418, in __init__\n",
      "    schema=sql_ctx._inferSchema(predictionAndLabels))\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/context.py\", line 227, in _inferSchema\n",
      "    return self.sparkSession._inferSchema(rdd, samplingRatio)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1464, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1446, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/context.py\", line 1118, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 128, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42305)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_21589/3603929504.py\", line 1, in <module>\n",
      "    ndcg = (evaluate_ndcg_at_k(model, full_matrix, train, test, k = 10))\n",
      "  File \"/tmp/ipykernel_21589/159118592.py\", line 3, in evaluate_ndcg_at_k\n",
      "    rank_eval = SparkRankingEvaluation(test, recommendations, k = k, col_user=\"UserID\", col_item=\"MovieID\",\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 284, in __init__\n",
      "    self._metrics = self._calculate_metrics()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 300, in _calculate_metrics\n",
      "    return RankingMetrics(self._items_for_user_all.rdd)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/mllib/evaluation.py\", line 418, in __init__\n",
      "    schema=sql_ctx._inferSchema(predictionAndLabels))\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/context.py\", line 227, in _inferSchema\n",
      "    return self.sparkSession._inferSchema(rdd, samplingRatio)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1464, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1446, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/context.py\", line 1118, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 128, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42305)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_21589/3603929504.py\", line 1, in <module>\n",
      "    ndcg = (evaluate_ndcg_at_k(model, full_matrix, train, test, k = 10))\n",
      "  File \"/tmp/ipykernel_21589/159118592.py\", line 3, in evaluate_ndcg_at_k\n",
      "    rank_eval = SparkRankingEvaluation(test, recommendations, k = k, col_user=\"UserID\", col_item=\"MovieID\",\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 284, in __init__\n",
      "    self._metrics = self._calculate_metrics()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 300, in _calculate_metrics\n",
      "    return RankingMetrics(self._items_for_user_all.rdd)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/mllib/evaluation.py\", line 418, in __init__\n",
      "    schema=sql_ctx._inferSchema(predictionAndLabels))\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/context.py\", line 227, in _inferSchema\n",
      "    return self.sparkSession._inferSchema(rdd, samplingRatio)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1464, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1446, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/context.py\", line 1118, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 128, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42305)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_21589/3603929504.py\", line 1, in <module>\n",
      "    ndcg = (evaluate_ndcg_at_k(model, full_matrix, train, test, k = 10))\n",
      "  File \"/tmp/ipykernel_21589/159118592.py\", line 3, in evaluate_ndcg_at_k\n",
      "    rank_eval = SparkRankingEvaluation(test, recommendations, k = k, col_user=\"UserID\", col_item=\"MovieID\",\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 284, in __init__\n",
      "    self._metrics = self._calculate_metrics()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 300, in _calculate_metrics\n",
      "    return RankingMetrics(self._items_for_user_all.rdd)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/mllib/evaluation.py\", line 418, in __init__\n",
      "    schema=sql_ctx._inferSchema(predictionAndLabels))\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/context.py\", line 227, in _inferSchema\n",
      "    return self.sparkSession._inferSchema(rdd, samplingRatio)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1464, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1446, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/context.py\", line 1118, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 128, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42305)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_21589/3603929504.py\", line 1, in <module>\n",
      "    ndcg = (evaluate_ndcg_at_k(model, full_matrix, train, test, k = 10))\n",
      "  File \"/tmp/ipykernel_21589/159118592.py\", line 3, in evaluate_ndcg_at_k\n",
      "    rank_eval = SparkRankingEvaluation(test, recommendations, k = k, col_user=\"UserID\", col_item=\"MovieID\",\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 284, in __init__\n",
      "    self._metrics = self._calculate_metrics()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 300, in _calculate_metrics\n",
      "    return RankingMetrics(self._items_for_user_all.rdd)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/mllib/evaluation.py\", line 418, in __init__\n",
      "    schema=sql_ctx._inferSchema(predictionAndLabels))\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/context.py\", line 227, in _inferSchema\n",
      "    return self.sparkSession._inferSchema(rdd, samplingRatio)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1464, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1446, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/context.py\", line 1118, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 128, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42305)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_21589/3603929504.py\", line 1, in <module>\n",
      "    ndcg = (evaluate_ndcg_at_k(model, full_matrix, train, test, k = 10))\n",
      "  File \"/tmp/ipykernel_21589/159118592.py\", line 3, in evaluate_ndcg_at_k\n",
      "    rank_eval = SparkRankingEvaluation(test, recommendations, k = k, col_user=\"UserID\", col_item=\"MovieID\",\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 284, in __init__\n",
      "    self._metrics = self._calculate_metrics()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py\", line 300, in _calculate_metrics\n",
      "    return RankingMetrics(self._items_for_user_all.rdd)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/mllib/evaluation.py\", line 418, in __init__\n",
      "    schema=sql_ctx._inferSchema(predictionAndLabels))\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/context.py\", line 227, in _inferSchema\n",
      "    return self.sparkSession._inferSchema(rdd, samplingRatio)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1464, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/rdd.py\", line 1446, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/context.py\", line 1118, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 128, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lap15450/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ndcg \u001b[39m=\u001b[39m (evaluate_ndcg_at_k(model, full_matrix, train, test, k \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m))\n",
      "Cell \u001b[0;32mIn [10], line 3\u001b[0m, in \u001b[0;36mevaluate_ndcg_at_k\u001b[0;34m(model, full_matrix, train, test, k)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate_ndcg_at_k\u001b[39m(model, full_matrix, train, test, k \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m):\n\u001b[1;32m      2\u001b[0m     recommendations \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mtransform(full_matrix)\n\u001b[0;32m----> 3\u001b[0m     rank_eval \u001b[39m=\u001b[39m SparkRankingEvaluation(test, recommendations, k \u001b[39m=\u001b[39;49m k, col_user\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mUserID\u001b[39;49m\u001b[39m\"\u001b[39;49m, col_item\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mMovieID\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[1;32m      4\u001b[0m                                     col_rating\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mRating\u001b[39;49m\u001b[39m\"\u001b[39;49m, col_prediction\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mprediction\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[1;32m      5\u001b[0m                                     relevancy_method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtop_k\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m rank_eval\u001b[39m.\u001b[39mndcg_at_k()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py:284\u001b[0m, in \u001b[0;36mSparkRankingEvaluation.__init__\u001b[0;34m(self, rating_true, rating_pred, k, relevancy_method, col_user, col_item, col_rating, col_prediction, threshold)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    261\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrelevancy_method should be one of \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    262\u001b[0m             \u001b[39mlist\u001b[39m(relevant_func\u001b[39m.\u001b[39mkeys())\n\u001b[1;32m    263\u001b[0m         )\n\u001b[1;32m    264\u001b[0m     )\n\u001b[1;32m    266\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrating_pred \u001b[39m=\u001b[39m (\n\u001b[1;32m    267\u001b[0m     relevant_func[relevancy_method](\n\u001b[1;32m    268\u001b[0m         dataframe\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrating_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m )\n\u001b[0;32m--> 284\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_calculate_metrics()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/recommenders/evaluation/spark_evaluation.py:300\u001b[0m, in \u001b[0;36mSparkRankingEvaluation._calculate_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_items_for_user_true \u001b[39m=\u001b[39m (\n\u001b[1;32m    291\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrating_true\u001b[39m.\u001b[39mgroupBy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcol_user)\n\u001b[1;32m    292\u001b[0m     \u001b[39m.\u001b[39magg(expr(\u001b[39m\"\u001b[39m\u001b[39mcollect_list(\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcol_item \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m) as ground_truth\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    293\u001b[0m     \u001b[39m.\u001b[39mselect(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcol_user, \u001b[39m\"\u001b[39m\u001b[39mground_truth\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    294\u001b[0m )\n\u001b[1;32m    296\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_items_for_user_all \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_items_for_user_pred\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m    297\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_items_for_user_true, on\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcol_user\n\u001b[1;32m    298\u001b[0m )\u001b[39m.\u001b[39mdrop(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcol_user)\n\u001b[0;32m--> 300\u001b[0m \u001b[39mreturn\u001b[39;00m RankingMetrics(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_items_for_user_all\u001b[39m.\u001b[39;49mrdd)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/mllib/evaluation.py:418\u001b[0m, in \u001b[0;36mRankingMetrics.__init__\u001b[0;34m(self, predictionAndLabels)\u001b[0m\n\u001b[1;32m    415\u001b[0m sc \u001b[39m=\u001b[39m predictionAndLabels\u001b[39m.\u001b[39mctx\n\u001b[1;32m    416\u001b[0m sql_ctx \u001b[39m=\u001b[39m SQLContext\u001b[39m.\u001b[39mgetOrCreate(sc)\n\u001b[1;32m    417\u001b[0m df \u001b[39m=\u001b[39m sql_ctx\u001b[39m.\u001b[39mcreateDataFrame(predictionAndLabels,\n\u001b[0;32m--> 418\u001b[0m                              schema\u001b[39m=\u001b[39msql_ctx\u001b[39m.\u001b[39;49m_inferSchema(predictionAndLabels))\n\u001b[1;32m    419\u001b[0m java_model \u001b[39m=\u001b[39m callMLlibFunc(\u001b[39m\"\u001b[39m\u001b[39mnewRankingMetrics\u001b[39m\u001b[39m\"\u001b[39m, df\u001b[39m.\u001b[39m_jdf)\n\u001b[1;32m    420\u001b[0m \u001b[39msuper\u001b[39m(RankingMetrics, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(java_model)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/context.py:227\u001b[0m, in \u001b[0;36mSQLContext._inferSchema\u001b[0;34m(self, rdd, samplingRatio)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_inferSchema\u001b[39m(\u001b[39mself\u001b[39m, rdd, samplingRatio\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    220\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[39m    Infer schema from an RDD of Row or tuple.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39m    :return: :class:`pyspark.sql.types.StructType`\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparkSession\u001b[39m.\u001b[39;49m_inferSchema(rdd, samplingRatio)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/session.py:396\u001b[0m, in \u001b[0;36mSparkSession._inferSchema\u001b[0;34m(self, rdd, samplingRatio, names)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_inferSchema\u001b[39m(\u001b[39mself\u001b[39m, rdd, samplingRatio\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, names\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    389\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[39m    Infer schema from an RDD of Row or tuple.\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[39m    :return: :class:`pyspark.sql.types.StructType`\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 396\u001b[0m     first \u001b[39m=\u001b[39m rdd\u001b[39m.\u001b[39;49mfirst()\n\u001b[1;32m    397\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m first:\n\u001b[1;32m    398\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe first row in RDD is empty, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m                          \u001b[39m\"\u001b[39m\u001b[39mcan not infer schema\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/rdd.py:1464\u001b[0m, in \u001b[0;36mRDD.first\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1453\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfirst\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1454\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1455\u001b[0m \u001b[39m    Return the first element in this RDD.\u001b[39;00m\n\u001b[1;32m   1456\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[39m    ValueError: RDD is empty\u001b[39;00m\n\u001b[1;32m   1463\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1464\u001b[0m     rs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtake(\u001b[39m1\u001b[39;49m)\n\u001b[1;32m   1465\u001b[0m     \u001b[39mif\u001b[39;00m rs:\n\u001b[1;32m   1466\u001b[0m         \u001b[39mreturn\u001b[39;00m rs[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/rdd.py:1446\u001b[0m, in \u001b[0;36mRDD.take\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   1443\u001b[0m         taken \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1445\u001b[0m p \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(partsScanned, \u001b[39mmin\u001b[39m(partsScanned \u001b[39m+\u001b[39m numPartsToTry, totalParts))\n\u001b[0;32m-> 1446\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcontext\u001b[39m.\u001b[39;49mrunJob(\u001b[39mself\u001b[39;49m, takeUpToNumLeft, p)\n\u001b[1;32m   1448\u001b[0m items \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m res\n\u001b[1;32m   1449\u001b[0m partsScanned \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m numPartsToTry\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/context.py:1118\u001b[0m, in \u001b[0;36mSparkContext.runJob\u001b[0;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[39m# Implementation note: This is implemented as a mapPartitions followed\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[39m# by runJob() in order to avoid having to pass a Python lambda into\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m \u001b[39m# SparkContext#runJob.\u001b[39;00m\n\u001b[1;32m   1117\u001b[0m mappedRDD \u001b[39m=\u001b[39m rdd\u001b[39m.\u001b[39mmapPartitions(partitionFunc)\n\u001b[0;32m-> 1118\u001b[0m sock_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jvm\u001b[39m.\u001b[39;49mPythonRDD\u001b[39m.\u001b[39;49mrunJob(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jsc\u001b[39m.\u001b[39;49msc(), mappedRDD\u001b[39m.\u001b[39;49m_jrdd, partitions)\n\u001b[1;32m   1119\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(_load_from_socket(sock_info, mappedRDD\u001b[39m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1298\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1303\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1304\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1305\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1307\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1308\u001b[0m     temp_arg\u001b[39m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/utils.py:128\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdeco\u001b[39m(\u001b[39m*\u001b[39ma, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw):\n\u001b[1;32m    127\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 128\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49ma, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    129\u001b[0m     \u001b[39mexcept\u001b[39;00m py4j\u001b[39m.\u001b[39mprotocol\u001b[39m.\u001b[39mPy4JJavaError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    130\u001b[0m         converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/protocol.py:334\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m. Trace:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{3}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m    332\u001b[0m                 \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name, value))\n\u001b[1;32m    333\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    335\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m    336\u001b[0m             \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name))\n\u001b[1;32m    337\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[39mtype\u001b[39m \u001b[39m=\u001b[39m answer[\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob"
     ]
    }
   ],
   "source": [
    "ndcg = (evaluate_ndcg_at_k(model, full_matrix, train, test, k = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = (evaluate_rmse(model, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_rate = (evaluate_hit_rate(als, left_out_dataframe, keep_one_dataframe, \\\n",
    "                                     full_matrix, n_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating, rank: {}, iter: {}, regParam: {}\".format(rank, iter, regParam))\n",
    "print(\"NDCG: {}, RMSE: {}, Hit: {}\".format(ndcg, rmse, hit_rate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
