{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf,col,collect_list\n",
    "from pyspark.sql.types import StringType, ArrayType, DoubleType,IntegerType\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RankingEvaluator\n",
    "from HR import HitRate\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "\n",
    "#For windows user only\n",
    "import os \n",
    "import sys\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\") \\\n",
    "                    .config('spark.ui.showConsoleProgress', 'false')\\\n",
    "                    .appName('MovieRecomender') \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema =             StructType([\n",
    "                    StructField('UserID', LongType(), True),\n",
    "                     StructField('MovieID', LongType(), True),\n",
    "                     StructField('Rating', IntegerType(), True),\n",
    "                     StructField('Timestamp', LongType(), True),\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"sep\", \"::\").schema(schema).csv(\"data/ratings.dat\")\n",
    "df.na.drop()\n",
    "df = df.toDF(*[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"])\n",
    "df.createOrReplaceTempView(\"dataset\");\n",
    "df = df.cache()\n",
    "df.count() #force cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hit Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql = '''\n",
    "# select \n",
    "#   A.UserID, A.MovieID, Rating, ROW_NUMBER() OVER (partition by A.UserID order by Rating desc) as RowNumber\n",
    "# from \n",
    "#   (\n",
    "#     select \n",
    "#       * \n",
    "#     from \n",
    "#       (\n",
    "#         select \n",
    "#           distinct(UserID) \n",
    "#         from \n",
    "#           dataset\n",
    "#       ), \n",
    "#       (\n",
    "#         select \n",
    "#           distinct(MovieID) \n",
    "#         from \n",
    "#           dataset\n",
    "#       )\n",
    "#   ) as A left outer join dataset as B\n",
    "#   on (A.UserID, A.MovieID) = (B.UserID, B.MovieID)\n",
    "# '''\n",
    "# full_matrix = spark.sql(sql)\n",
    "# full_matrix.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(userCol=\"UserID\", itemCol=\"MovieID\", ratingCol=\"Rating\", nonnegative = True, implicitPrefs = False,coldStartStrategy=\"drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_evaluator = HitRate(predictionCol='prediction', labelCol='Rating', userCol='UserID', itemCol = \"MovieID\")\n",
    "value = hr_evaluator.eval(als, df)\n",
    "print(\"Hit rate is {}\".format(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSE and NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, test) = df.randomSplit([0.8, 0.2])\n",
    "grid_search = ParamGridBuilder().addGrid(als.rank,[50]).addGrid(als.maxIter,[15]).addGrid(als.regParam, [0.05] ).build()\n",
    "# Thay đổi params ở đây"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = RegressionEvaluator(metricName=\"rmse\", labelCol=\"Rating\", predictionCol=\"prediction\") \n",
    "ndcg = RankingEvaluator(labelCol=\"RealRank\", predictionCol=\"recommendations\",metricName=\"ndcgAtK\", k=10)\n",
    "# cv = CrossValidator(estimator=als, estimatorParamMaps=grid_search, evaluator=rmse, numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.setCheckpointDir('checkpoint/')\n",
    "model=als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRank(a):\n",
    "    ret=[]\n",
    "    for i in a:\n",
    "        ret.append(float(i.MovieID))\n",
    "    return ret\n",
    "convertUDF = udf(lambda z: getRank(z),ArrayType(DoubleType()))\n",
    "\n",
    "def toDouble(a):\n",
    "    return [float(i) for i in a]\n",
    "toDoubleUDF = udf(lambda z: toDouble(z),ArrayType(DoubleType()))\n",
    "\n",
    "tempt=df.sort(col('Rating').desc()).groupBy(\"UserID\").agg(collect_list('MovieID').alias(\"RealRank\"))\n",
    "tempt=tempt.withColumn(\"RealRank\",toDoubleUDF(col(\"RealRank\")))\n",
    "\n",
    "rec=model.recommendForAllUsers(3952).join(tempt,\"UserID\",\"inner\")\n",
    "rec=rec.withColumn(\"recommendations\",convertUDF(col(\"recommendations\")))\n",
    "rec.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.transform(test).na.drop()\n",
    "print(rmse.evaluate(predictions),ndcg.evaluate(rec))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "124abba6514438ab53c11acaf3afc05fa2c91147de36b77a0837384a6fb18358"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
