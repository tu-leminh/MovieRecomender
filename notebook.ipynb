{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 23:02:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "<SparkContext master=local[2] appName=MovieRecomender>\n",
      "Spark App Name : MovieRecomender\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[2]\") \\\n",
    "                    .appName('MovieRecomender') \\\n",
    "                    .getOrCreate()\n",
    "print(spark.sparkContext)\n",
    "print(\"Spark App Name : \"+ spark.sparkContext.appName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mt/MovieRecomender'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.chdir ('/home/mt/MovieRecomender')\n",
    "#change to your working directory\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = pd.read_csv(\"data/movies.dat\", engine='python', sep='::', names=[\"MovieID\", \"Title\", \"Genres\"],encoding='ISO-8859-1')\n",
    "df_m = spark.createDataFrame(df_m)\n",
    "\n",
    "df_r = pd.read_csv(\"data/ratings.dat\", engine='python', sep='::', names=[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"])\n",
    "df_r = spark.createDataFrame(df_r)\n",
    "\n",
    "df_u = pd.read_csv(\"data/users.dat\", engine='python', sep='::', names=[\"UserID\", \"Gender\", \"Age\", \"Occupation\", \"Zip-code\"])\n",
    "df_u = spark.createDataFrame(df_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MovieID: long (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Genres: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|MovieID|               Title|              Genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Animation|Childre...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_m.printSchema()\n",
    "df_m.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- UserID: long (nullable = true)\n",
      " |-- MovieID: long (nullable = true)\n",
      " |-- Rating: long (nullable = true)\n",
      " |-- Timestamp: long (nullable = true)\n",
      "\n",
      "22/10/04 23:02:46 WARN TaskSetManager: Stage 1 contains a task of very large size (7756 KiB). The maximum recommended task size is 1000 KiB.\n",
      "+------+-------+------+---------+\n",
      "|UserID|MovieID|Rating|Timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|   1193|     5|978300760|\n",
      "|     1|    661|     3|978302109|\n",
      "|     1|    914|     3|978301968|\n",
      "+------+-------+------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_r.printSchema()\n",
    "df_r.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- UserID: long (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Age: long (nullable = true)\n",
      " |-- Occupation: long (nullable = true)\n",
      " |-- Zip-code: string (nullable = true)\n",
      "\n",
      "+------+------+---+----------+--------+\n",
      "|UserID|Gender|Age|Occupation|Zip-code|\n",
      "+------+------+---+----------+--------+\n",
      "|     1|     F|  1|        10|   48067|\n",
      "|     2|     M| 56|        16|   70072|\n",
      "|     3|     M| 25|        15|   55117|\n",
      "+------+------+---+----------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_u.printSchema()\n",
    "df_u.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- UserID: long (nullable = true)\n",
      " |-- MovieID: long (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Genres: string (nullable = true)\n",
      " |-- Rating: long (nullable = true)\n",
      " |-- Timestamp: long (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Age: long (nullable = true)\n",
      " |-- Occupation: long (nullable = true)\n",
      " |-- Zip-code: string (nullable = true)\n",
      "\n",
      "22/10/04 23:02:48 WARN TaskSetManager: Stage 4 contains a task of very large size (7756 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------------------+--------------------+------+---------+------+---+----------+--------+\n",
      "|UserID|MovieID|               Title|              Genres|Rating|Timestamp|Gender|Age|Occupation|Zip-code|\n",
      "+------+-------+--------------------+--------------------+------+---------+------+---+----------+--------+\n",
      "|     5|     29|City of Lost Chil...|    Adventure|Sci-Fi|     5|978245065|     M| 25|        20|   55455|\n",
      "|     6|   1806|       Paulie (1998)|Adventure|Childre...|     3|978236876|     F| 50|         9|   55117|\n",
      "|     7|    474|In the Line of Fi...|     Action|Thriller|     5|978234842|     M| 35|         1|   06810|\n",
      "+------+-------+--------------------+--------------------+------+---------+------+---+----------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=df_m.join(df_r,\"MovieID\",\"inner\").join(df_u,\"UserID\",\"inner\")\n",
    "df.printSchema()\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 23:02:50 WARN TaskSetManager: Stage 13 contains a task of very large size (7756 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|UserID|MovieID|Rating|\n",
      "+------+-------+------+\n",
      "|    26|   3506|     4|\n",
      "|    29|    474|     2|\n",
      "|    29|   2529|     5|\n",
      "+------+-------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=df.select([\"UserID\",\"MovieID\",\"Rating\"])\n",
    "df.na.drop()\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, test) = df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(userCol=\"UserID\", itemCol=\"MovieID\", ratingCol=\"Rating\", nonnegative = True, implicitPrefs = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = ParamGridBuilder().addGrid(als.rank, [10, 25, 50 ,75 , 100]  ).addGrid(als.maxIter,[5, 10, 20, 40, 80, 160]  ).addGrid(als.regParam, [.001,.005,.01, .05, .1, .5] ).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"Rating\", predictionCol=\"prediction\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidator(estimator=als, estimatorParamMaps=grid_search, evaluator=evaluator, numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 23:02:53 WARN TaskSetManager: Stage 26 contains a task of very large size (7756 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 23:03:07 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/10/04 23:03:07 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "22/10/04 23:03:10 WARN TaskSetManager: Stage 95 contains a task of very large size (7756 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sparkContext.setCheckpointDir('checkpoint/')\n",
    "cv_fitted=cv.fit(train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c650872fe48c780013875d4f984f728941c1d311640e7eee5c7ccd41a2e181b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
