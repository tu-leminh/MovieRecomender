{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from hit_rate import HitRate\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\") \\\n",
    "                    .config('spark.ui.showConsoleProgress', 'false')\\\n",
    "                    .appName('MovieRecomender') \\\n",
    "                    .getOrCreate()\n",
    "print(spark.sparkContext)\n",
    "print(\"Spark App Name : \"+ spark.sparkContext.appName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/ratings.dat\", engine='python', sep='::', names=[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"])\n",
    "df=df.select([\"UserID\",\"MovieID\",\"Rating\"])\n",
    "df.na.drop()\n",
    "df = spark.createDataFrame(df)\n",
    "df.createOrReplaceTempView(\"dataset\");\n",
    "df = df.cache()\n",
    "df.count() #force cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "select \n",
    "  A.UserID, A.MovieID, Rating\n",
    "from \n",
    "  (\n",
    "    select \n",
    "      * \n",
    "    from \n",
    "      (\n",
    "        select \n",
    "          distinct(UserID) \n",
    "        from \n",
    "          dataset\n",
    "      ), \n",
    "      (\n",
    "        select \n",
    "          distinct(MovieID) \n",
    "        from \n",
    "          dataset\n",
    "      )\n",
    "  ) as A left outer join dataset as B\n",
    "  on (A.UserID, A.MovieID) = (B.UserID, B.MovieID)\n",
    "'''\n",
    "full_matrix = spark.sql(sql)\n",
    "full_matrix.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_matrix.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave one out for each group in full_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loo_matrix = full_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, test) = df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(userCol=\"UserID\", itemCol=\"MovieID\", ratingCol=\"Rating\", nonnegative = True, implicitPrefs = False,coldStartStrategy=\"drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = ParamGridBuilder().addGrid(als.rank,[30,50]).addGrid(als.maxIter,[15,20,50]).addGrid(als.regParam, [0.05] ).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"Rating\", predictionCol=\"prediction\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidator(estimator=als, estimatorParamMaps=grid_search, evaluator=evaluator, numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.setCheckpointDir('checkpoint/')\n",
    "cv_fitted=cv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv_fitted.bestModel.rank, cv_fitted.bestModel._java_obj.parent().getMaxIter(),cv_fitted.bestModel._java_obj.parent().getRegParam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evaluate(cv_fitted.transform(test).na.drop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_evaluator = HitRate(predictionCol='prediction', labelCol='rating', userCol='userId')\n",
    "model = als.fit(train)\n",
    "predictions = model.transform(test)\n",
    "hr_evaluator.evaluate(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "124abba6514438ab53c11acaf3afc05fa2c91147de36b77a0837384a6fb18358"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
